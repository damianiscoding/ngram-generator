{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "613e9ae7-60e6-492c-8f58-959eae39551f",
      "metadata": {
        "id": "613e9ae7-60e6-492c-8f58-959eae39551f"
      },
      "source": [
        "## Install Requirements\n",
        "Run the cell, below, to install the libraries we'll be using."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "337b586e-c781-49fc-a60e-bc13ce4e78e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "337b586e-c781-49fc-a60e-bc13ce4e78e9",
        "outputId": "751b6d8d-ce41-4e32-96c6-fa9fc39e3f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/414.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m409.6/414.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m414.3/414.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m153.7/153.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.16 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install -qU langchain langchain-core langchain_community langchain_text_splitters langgraph\n",
        "%pip install -qU langchain-google-genai\n",
        "%pip install -qU bs4\n",
        "%pip install -qU python-dotenv typing_extensions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d372d5e7-db78-4e70-abcb-527ed3172fb5",
      "metadata": {
        "id": "d372d5e7-db78-4e70-abcb-527ed3172fb5"
      },
      "source": [
        "## Load the API key into the environment\n",
        "The code, below, loads the API key and stores it where the LangChain libraries (and likely the Google libraries used by the LangChain libraries) expect to find it.\n",
        "\n",
        "**If you're running this code in Google Colab**, this code assumes you've already stored your API key as a *secret*:\n",
        "\n",
        "1. Open your Google Colab notebook and click on the üîë Secrets tab in the left panel.\n",
        "2. The Secrets tab is found on the left panel.\n",
        "3. Create a new secret with the name `GOOGLE_API_KEY`.\n",
        "4. Copy/paste your API key into the Value input box of `GOOGLE_API_KEY`.\n",
        "5. Toggle the button on the left to allow notebook access to the secret.\n",
        "\n",
        "Otherwise, the code assumes that you have a `.env` file that includes `GOOGLE_API_KEY=<your api key here>`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c8e14fed-2868-4890-b286-36cb11a77551",
      "metadata": {
        "id": "c8e14fed-2868-4890-b286-36cb11a77551"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "API_KEY = 'GOOGLE_API_KEY'\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import userdata\n",
        "    os.environ[API_KEY] = userdata.get(API_KEY)\n",
        "    os.environ[API_KEY]\n",
        "else:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()  # Load environment variables from .env file; should include GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ea1eea1-5beb-4ea6-bdb2-e58b77b43364",
      "metadata": {
        "id": "2ea1eea1-5beb-4ea6-bdb2-e58b77b43364"
      },
      "source": [
        "You can verify that your API key is where it ought to be by uncommenting and running the code cell, below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ec2eff26-1a8b-4df4-9148-faeb91c64fcb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ec2eff26-1a8b-4df4-9148-faeb91c64fcb",
        "outputId": "df9f6762-a718-47d2-f0fb-94d58c493142"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AIzaSyAFd3jwgT_lEzNImSSMf57cSUWHligw6mQ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.getenv(API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6be63fe-dfa6-43f6-847d-89ce013c82a6",
      "metadata": {
        "id": "d6be63fe-dfa6-43f6-847d-89ce013c82a6"
      },
      "source": [
        "## Components\n",
        "Import and instantiate a:\n",
        "  1. chat model\n",
        "  2. embedding model\n",
        "  3. in-memory vector store\n",
        "\n",
        "Note that we're using the `langchain_google_genai` library instead of the Google Vertex (or OpenAI, or Anthropic, etc.) library. That means you can't simply copy code from the LangChain tutorial. Documentation for the Google GenAI library can be found [here](https://python.langchain.com/api_reference/google_genai/index.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0a0f543d-f139-49a6-a445-a15a0d6e5f25",
      "metadata": {
        "id": "0a0f543d-f139-49a6-a445-a15a0d6e5f25"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite-preview-02-05\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "53cf1193-4665-48bd-83e1-c7ffa58fbd00",
      "metadata": {
        "id": "53cf1193-4665-48bd-83e1-c7ffa58fbd00"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5203071a-d2a5-4c04-b4c8-6400a1b1dc83",
      "metadata": {
        "id": "5203071a-d2a5-4c04-b4c8-6400a1b1dc83"
      },
      "outputs": [],
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "278cf55a-d311-43da-bce6-438e70b9ca26",
      "metadata": {
        "id": "278cf55a-d311-43da-bce6-438e70b9ca26"
      },
      "source": [
        "## RAG Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e2ed668-0ced-44cb-afe4-61f9e6f23d90",
      "metadata": {
        "id": "7e2ed668-0ced-44cb-afe4-61f9e6f23d90"
      },
      "source": [
        "### Scrape a Web Page\n",
        "\n",
        "We'll use the `WebBaseLoader` class to scrape a web page we'd like to ask an LLM about. It uses [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/) -- another popular library -- to parse the web page (extract its text content).\n",
        "\n",
        "Notice how, instead of writing their own HTML parser, the LangChain developers make use of another well-established library. The named parameter `bs_kwargs` is short for \"Beautiful Soup key-word arguments. We're passing to `WebBaseLoader` a set of arguments that will be passed to Beautiful Soup functions. A decision to use another library like this comes with trade-offs:\n",
        "  - To use LangChain, I don't have to write much or any code to control Beautiful Soup. LangChain handles (almost) all of it for me.\n",
        "  - But now this LangChain class is dependent on (tied to) Beautiful Soup. If Beautiful Soup changes interfaces, `WebBaseLoader` might break.\n",
        "  - And `WebBaseLoader` is also somewhat less flexible. What if Beautiful Soup isn't my prefered library or doesn't do what I need? So you'll sometimes see one library give you the ability to pass whatever HTML parser you choose. It could be Beautiful Soup or another open-source library or the HTML parser you wrote for fun.\n",
        "\n",
        "Notice also that we've decided to give Beautiful Soup some more specific instructions, taking content from HTML tags that have a class of `post-content`, `post-title`, or `post-header`. (You could navigate to the web page and open the developer tools to see just what that includes.) Doing so gives us cleaner text to use for our RAG application but at the cost of making our code less general. If I want to query a different web page, there's no reason to think it will use the same class names to identify the important bits. If we add a web page loader to KnotebookLM, we'll need to think about how best to generalize our approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b8bc34ac-f19c-40e0-a10e-f4712b208f6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8bc34ac-f19c-40e0-a10e-f4712b208f6b",
        "outputId": "4a002c8b-59f1-4336-c488-5f5578d56be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# setting a User-Agent to avoid a Beautiful Soup warning\n",
        "# a User-Agent header tells a web server what kind of client is making the request\n",
        "os.environ['USER_AGENT'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        ),\n",
        "    ),\n",
        ")\n",
        "\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "443664c2-7f19-42ec-b78e-cc05d6c0005c",
      "metadata": {
        "id": "443664c2-7f19-42ec-b78e-cc05d6c0005c"
      },
      "source": [
        "`docs` is a list of `Document` objects. We only loaded one document, so the length of `docs` is 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "978e6729-d8a7-4fb1-81a7-eb2c61c211ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "978e6729-d8a7-4fb1-81a7-eb2c61c211ad",
        "outputId": "a228abb9-2228-4bd3-a0bb-d155f49eb457"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1398b08c-5ce1-41a0-8ea4-da57c5183b98",
      "metadata": {
        "id": "1398b08c-5ce1-41a0-8ea4-da57c5183b98"
      },
      "source": [
        "We can ask Python to tell us the type of that sole document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e52be27e-69bf-40b8-9950-c353492c3613",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "e52be27e-69bf-40b8-9950-c353492c3613",
        "outputId": "f10af722-7076-4ab9-d1bb-c42e4bb0fad8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.documents.base.Document"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.documents.base.Document</b><br/>def __init__(page_content: str, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/langchain_core/documents/base.py</a>Class for storing a piece of text and associated metadata.\n",
              "\n",
              "Example:\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        from langchain_core.documents import Document\n",
              "\n",
              "        document = Document(\n",
              "            page_content=&quot;Hello, world!&quot;,\n",
              "            metadata={&quot;source&quot;: &quot;https://example.com&quot;}\n",
              "        )</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 262);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "type(docs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92fb85ca-d2d2-4ba3-937c-e755dd436bc3",
      "metadata": {
        "id": "92fb85ca-d2d2-4ba3-937c-e755dd436bc3"
      },
      "source": [
        "That's `langchain-core`'s base `Document` class. Consulting the [documentation](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document) you can see it is instantiated with two notable properties: `page_content` and `metadata`. (You can also find in the documentation a link to the source code if you want to dig further.)\n",
        "\n",
        "We'll need to talk about `metadata` later. For now, let's look at the first bit of the `page_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1ee9db16-c120-4605-8ab0-bf9b01e3e24e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1ee9db16-c120-4605-8ab0-bf9b01e3e24e",
        "outputId": "1004ee10-9cb9-4517-fcc4-74720cf8d2fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "docs[0].page_content[1300:1500]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a75bc8f2-38cf-4435-bf9e-eae4aa7fcf12",
      "metadata": {
        "id": "a75bc8f2-38cf-4435-bf9e-eae4aa7fcf12"
      },
      "source": [
        "Compare it to the web page we scraped. Beautiful Soup did a pretty good job, no?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d979cb17-906f-4f88-8e6a-4a1dda941b70",
      "metadata": {
        "id": "d979cb17-906f-4f88-8e6a-4a1dda941b70"
      },
      "source": [
        "### Split the Text\n",
        "As a final pre-processing step, we'll split the text into smaller chunks. Read [why](https://python.langchain.com/docs/concepts/text_splitters/#why-split-documents).\n",
        "\n",
        "Following the tutorial, we'll use the `RecursiveCharacterTextSplitter` class. It implements a [text-structure based](https://python.langchain.com/docs/concepts/text_splitters/#text-structured-based) approach. To better understand how this splitter works and how to control it, read this [guide](https://python.langchain.com/docs/how_to/recursive_text_splitter/) and consult the [documentation](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "4ef62a9f-fd2b-4a9a-8053-3beec03d663d",
      "metadata": {
        "id": "4ef62a9f-fd2b-4a9a-8053-3beec03d663d"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "all_splits = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10418d2a-e88b-4928-b9bb-362465c61ccf",
      "metadata": {
        "id": "10418d2a-e88b-4928-b9bb-362465c61ccf"
      },
      "source": [
        "Let's see how many chunks we've split our document into."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "94ba6483-5741-455f-82e6-85702913123f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ba6483-5741-455f-82e6-85702913123f",
        "outputId": "4e7987c5-6952-4c3c-cf1e-ff3616300b37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "len(all_splits)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_splits[49:55]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnIOQU5c2ova",
        "outputId": "f53664f6-0995-4efa-eef4-ae0093221843"
      },
      "id": "mnIOQU5c2ova",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code‚Äôs language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the ‚Äúentrypoint‚Äù file, then go to the ones that are imported by that file, and so on.'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='FILENAME\\nCODE\\nYou will start with the ‚Äúentrypoint‚Äù file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='You always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='pytest\\ndataclasses'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Conversatin samples:\\n[\\n  {\\n    \"role\": \"system\",'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f270c46-f04d-420e-9d4f-ca0946d902f7",
      "metadata": {
        "id": "8f270c46-f04d-420e-9d4f-ca0946d902f7"
      },
      "source": [
        "They're not all equal length. Based on the guides and documentation you've read, can you explain why?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "323611eb-b7ce-4a51-86a2-12b98527d8ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "323611eb-b7ce-4a51-86a2-12b98527d8ae",
        "outputId": "054724b7-4e6a-411a-8edc-41d91370b310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 0 length: 969\n",
            "Split 1 length: 609\n",
            "Split 2 length: 606\n",
            "Split 3 length: 644\n",
            "Split 4 length: 971\n",
            "Split 5 length: 506\n",
            "Split 6 length: 902\n",
            "Split 7 length: 706\n",
            "Split 8 length: 164\n",
            "Split 9 length: 960\n",
            "Split 10 length: 412\n",
            "Split 11 length: 903\n",
            "Split 12 length: 834\n",
            "Split 13 length: 545\n",
            "Split 14 length: 969\n",
            "Split 15 length: 986\n",
            "Split 16 length: 459\n",
            "Split 17 length: 542\n",
            "Split 18 length: 760\n",
            "Split 19 length: 772\n",
            "Split 20 length: 818\n",
            "Split 21 length: 469\n",
            "Split 22 length: 655\n",
            "Split 23 length: 820\n",
            "Split 24 length: 476\n",
            "Split 25 length: 388\n",
            "Split 26 length: 855\n",
            "Split 27 length: 805\n",
            "Split 28 length: 639\n",
            "Split 29 length: 456\n",
            "Split 30 length: 610\n",
            "Split 31 length: 616\n",
            "Split 32 length: 679\n",
            "Split 33 length: 726\n",
            "Split 34 length: 971\n",
            "Split 35 length: 195\n",
            "Split 36 length: 997\n",
            "Split 37 length: 828\n",
            "Split 38 length: 624\n",
            "Split 39 length: 955\n",
            "Split 40 length: 541\n",
            "Split 41 length: 961\n",
            "Split 42 length: 704\n",
            "Split 43 length: 556\n",
            "Split 44 length: 958\n",
            "Split 45 length: 666\n",
            "Split 46 length: 664\n",
            "Split 47 length: 983\n",
            "Split 48 length: 127\n",
            "Split 49 length: 936\n",
            "Split 50 length: 999\n",
            "Split 51 length: 310\n",
            "Split 52 length: 18\n",
            "Split 53 length: 48\n",
            "Split 54 length: 991\n",
            "Split 55 length: 996\n",
            "Split 56 length: 476\n",
            "Split 57 length: 702\n",
            "Split 58 length: 989\n",
            "Split 59 length: 378\n",
            "Split 60 length: 132\n",
            "Split 61 length: 808\n",
            "Split 62 length: 568\n",
            "Split 63 length: 976\n",
            "Split 64 length: 956\n",
            "Split 65 length: 940\n"
          ]
        }
      ],
      "source": [
        "for idx, split in enumerate(all_splits):\n",
        "    print(f\"Split {idx} length: {len(split.page_content)}\")#, all_splits[53])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af1ee6fb-70f6-4ce7-8c4d-308a5bbeafc2",
      "metadata": {
        "id": "af1ee6fb-70f6-4ce7-8c4d-308a5bbeafc2"
      },
      "source": [
        "Based on what we read, we'd expect to see some overlap between the end of one split and the beginning of the next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "54720d22-28ec-4ccb-981d-1c0f4f0bbe97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54720d22-28ec-4ccb-981d-1c0f4f0bbe97",
        "outputId": "a220bf4e-6b8f-492f-ef29-2e1a7c8d5ccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "previous: \n",
            " ined\n",
            "package/project.\n",
            "Python toolbelt preferences: \n",
            "\n",
            "current: \n",
            " pytest\n",
            "dataclasses \n",
            "\n",
            "\n",
            "------------------\n",
            "\n",
            "previous: \n",
            " pytest\n",
            "dataclasses \n",
            "\n",
            "current: \n",
            " Conversatin samples:\n",
            "[\n",
            "  {\n",
            "    \"role\": \"system\", \n",
            "\n",
            "\n",
            "------------------\n",
            "\n",
            "previous: \n",
            " Conversatin samples:\n",
            "[\n",
            "  {\n",
            "    \"role\": \"system\", \n",
            "\n",
            "current: \n",
            " \"content\": \"You will get instructions for code to  \n",
            "\n",
            "\n",
            "------------------\n",
            "\n",
            "previous: \n",
            " that are imported by that file, and so on.\\nPlease \n",
            "\n",
            "current: \n",
            " for the code's language, and CODE is the code:\\n\\n \n",
            "\n",
            "\n",
            "------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for prev, curr in zip(all_splits[51:55], all_splits[52:56]):\n",
        "    print('previous: \\n', prev.page_content[-50:], '\\n')\n",
        "    print('current: \\n', curr.page_content[:50], '\\n')\n",
        "    print('\\n------------------\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c392ee3-77d3-4c6f-a76a-bcf0bfb9a8bf",
      "metadata": {
        "id": "0c392ee3-77d3-4c6f-a76a-bcf0bfb9a8bf"
      },
      "source": [
        "But in this slice of splits, I don't see any overlap. (I tried a few different slices and likewise didn't see any overlaps.) Does that mean it's not working?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "4a90f378-4273-4527-bde4-ced79b586318",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a90f378-4273-4527-bde4-ced79b586318",
        "outputId": "8a252f70-db55-40df-b1a0-b8fbd3c0554d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------- index 0 ----------\n",
            "\n",
            "previous: \n",
            " Memory \n",
            "\n",
            "current: \n",
            " Memory \n",
            "\n",
            "\n",
            "-------- index 39 ----------\n",
            "\n",
            "previous: \n",
            " GOALS: \n",
            "\n",
            "current: \n",
            " GOALS: \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range (len(all_splits) - 1):\n",
        "    last = all_splits[i].page_content.strip().split()[-1]\n",
        "    first = all_splits[i+1].page_content.strip().split()[0]\n",
        "    if last == first:\n",
        "        print('\\n-------- index', i, '----------\\n')\n",
        "        print('previous: \\n', last, '\\n')\n",
        "        print('current: \\n', first, '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d93ae62-278a-4ead-9089-49aae6098663",
      "metadata": {
        "id": "4d93ae62-278a-4ead-9089-49aae6098663"
      },
      "source": [
        "There are only two cases where one split overlaps with the previous, and in both cases it looks like a heading. It's not perfectly clear -- at least not to me -- why `RecursiveCharacterTextSplitter` works this way. It could be the nature of the web page (lots of headings, lots of figures). It could be our the relation between our `chunk_size` and `chunk_overlap`. The documentation isn't super helpful. If we want to know more, we'll likely have to dive into the code and experiment.\n",
        "\n",
        "When it comes time to write code for KnotebookLM, we'll likely want to play around with chunk and overlap sizes and see what makes most sense for our application."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20980be4-adaa-4630-860f-b69dcd236804",
      "metadata": {
        "id": "20980be4-adaa-4630-860f-b69dcd236804"
      },
      "source": [
        "### Index Splits\n",
        "\n",
        "If you were implementing this next step without LangChain, you'd likely think of it as two steps:\n",
        "1. For each split, generate an embedding (a vector that represents the \"meaning\" of the text in the split)\n",
        "2. Write the resulting vector and the original text to a database.\n",
        "\n",
        "LangChain handles both with a single call to the `add_documents` method on the `vector_store` instance we created. (And now you understand why we needed to pass the `embeddings` instance as an argument to `vector_store`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "387b14fc-1154-4690-8548-62aaf61e06ad",
      "metadata": {
        "id": "387b14fc-1154-4690-8548-62aaf61e06ad"
      },
      "outputs": [],
      "source": [
        "_ = vector_store.add_documents(documents=all_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d2d870-7e4c-4763-9872-bc5da8ddb48b",
      "metadata": {
        "id": "68d2d870-7e4c-4763-9872-bc5da8ddb48b"
      },
      "source": [
        "That's all the pre-processing we need. We're ready to move on to retrieval tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc8d2856-3dac-40ee-8cd3-3c836d0b72d4",
      "metadata": {
        "id": "bc8d2856-3dac-40ee-8cd3-3c836d0b72d4"
      },
      "source": [
        "## Retrieve Relevant Chunks, Ask Questions\n",
        "\n",
        "We've indexed the web page and can now ask questions."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "749c9354-9ca6-4d99-b033-2cbcf6ecec2c",
      "metadata": {
        "id": "749c9354-9ca6-4d99-b033-2cbcf6ecec2c"
      },
      "source": [
        "### Prompt\n",
        "\n",
        "LangChain has a library of task-specific prompts. Let's grab the \"RAG\" prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "3f690343-da3f-41f7-9d22-484517157900",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f690343-da3f-41f7-9d22-484517157900",
        "outputId": "f0cf8800-040c-4762-a486-42ecbaef4912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "prompt = hub.pull('rlm/rag-prompt');\n",
        "prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "379f61ce-7b1a-4f89-aba0-3435885a6dc7",
      "metadata": {
        "id": "379f61ce-7b1a-4f89-aba0-3435885a6dc7"
      },
      "source": [
        "Notice it didn't return a simple string, but rather an instance of `ChatPromptTemplate`. Following the tutorial's walk-through, we can explore it a bit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "71d03ce4-73dc-4cc1-9c21-ffb132c82808",
      "metadata": {
        "id": "71d03ce4-73dc-4cc1-9c21-ffb132c82808"
      },
      "outputs": [],
      "source": [
        "example_message, = prompt.invoke(\n",
        "    { \"context\": \"Here's where we'll put relevant chunks from the web page.\", \"question\": \"Here's where our question goes.\" }\n",
        ").to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b550908-7101-444b-96b0-81dcb651898e",
      "metadata": {
        "id": "0b550908-7101-444b-96b0-81dcb651898e"
      },
      "source": [
        "Notice the comma after `example_message`? That wasn't a mistake. As `to_messages` implies, we might get more than one message. Adding the comma there *destructures* the list `to_messages` returns so that I get just the first item. (In this case, there is only one item.)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af02ae57-0e11-4f70-af1e-619dc719de6c",
      "metadata": {
        "id": "af02ae57-0e11-4f70-af1e-619dc719de6c"
      },
      "source": [
        "Let's see the `content` of that message..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "2d120448-9c8e-428a-bf5e-e2d69480d804",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d120448-9c8e-428a-bf5e-e2d69480d804",
        "outputId": "2aef4fcf-ee7b-4a4d-87fb-4d60472e13a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: Here's where our question goes. \n",
            "Context: Here's where we'll put relevant chunks from the web page. \n",
            "Answer:\n"
          ]
        }
      ],
      "source": [
        "print(example_message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f404ced-ca53-495c-98f9-108350a02193",
      "metadata": {
        "id": "0f404ced-ca53-495c-98f9-108350a02193"
      },
      "source": [
        "Pretty cool. We pass the prompt a dictionary with `context` and `question` keys and it'll insert their values into our prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06478a0c-43bb-4ae0-9414-4ca90c720279",
      "metadata": {
        "id": "06478a0c-43bb-4ae0-9414-4ca90c720279"
      },
      "source": [
        "### Using LangGraph to Stitch Together the Parts"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}